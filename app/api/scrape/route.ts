// ================================================================================
// API ROUTE: /api/scrape
// Triggers scraping of MDN documentation
// ================================================================================

import { NextRequest, NextResponse } from 'next/server'
import { supabaseAdmin } from '@/lib/supabase'
import { mdnScraper } from '@/lib/mdn-scraper'

export const maxDuration = 300 // 5 minutes
export const dynamic = 'force-dynamic'

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { sectionSlug, priority = 5 } = body

    if (!sectionSlug) {
      return NextResponse.json({ error: 'sectionSlug is required' }, { status: 400 })
    }

    // Get or create knowledge source for MDN
    let sourceId: string

    const { data: existingSource } = await supabaseAdmin
      .from('knowledge_sources')
      .select('id')
      .eq('url', 'https://developer.mozilla.org')
      .single()

    if (existingSource) {
      sourceId = existingSource.id
    } else {
      const { data: newSource, error: createError } = await supabaseAdmin
        .from('knowledge_sources')
        .insert({
          name: 'MDN Web Docs',
          source_type: 'documentation',
          url: 'https://developer.mozilla.org',
          base_domain: 'developer.mozilla.org',
          category: 'web_development',
          priority,
          trust_level: 'verified',
          status: 'active',
          scrape_enabled: true,
          scrape_frequency: 'weekly',
          tags: ['mdn', 'web-development', 'html', 'css', 'javascript'],
        })
        .select('id')
        .single()

      if (createError || !newSource) {
        throw new Error('Failed to create knowledge source')
      }

      sourceId = newSource.id
    }

    // Create scraping job
    const { data: job, error: jobError } = await supabaseAdmin
      .from('scraping_jobs')
      .insert({
        source_id: sourceId,
        job_type: 'full_scrape',
        scheduled_at: new Date().toISOString(),
        status: 'pending',
        total_urls: 0,
        urls_processed: 0,
        urls_failed: 0,
        progress_percentage: 0,
        items_scraped: 0,
        items_new: 0,
        items_updated: 0,
        items_unchanged: 0,
        retry_count: 0,
        max_retries: 3,
        config: { sectionSlug },
      })
      .select()
      .single()

    if (jobError || !job) {
      throw new Error('Failed to create scraping job')
    }

    // Start scraping in background
    scrapeInBackground(job.id, sectionSlug, sourceId)

    return NextResponse.json({
      success: true,
      jobId: job.id,
      message: `Scraping started for ${sectionSlug}`,
    })
  } catch (error) {
    console.error('Scrape API error:', error)
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    )
  }
}

export async function GET() {
  try {
    // Get list of available sections
    const sections = await mdnScraper.getMDNSections()

    // Get already scraped sections
    const { data: scrapedJobs } = await supabaseAdmin
      .from('scraping_jobs')
      .select('config, status')
      .eq('status', 'completed')

    const scrapedSections = new Set(
      scrapedJobs?.map((job: any) => job.config?.sectionSlug).filter(Boolean) || []
    )

    // Mark which sections are already scraped
    const sectionsWithStatus = sections.map((section) => ({
      ...section,
      scraped: scrapedSections.has(section.slug),
    }))

    return NextResponse.json({
      success: true,
      count: sections.length,
      sections: sectionsWithStatus,
    })
  } catch (error) {
    console.error('Get sections API error:', error)
    return NextResponse.json(
      { error: error instanceof Error ? error.message : 'Unknown error' },
      { status: 500 }
    )
  }
}

async function scrapeInBackground(jobId: string, sectionSlug: string, sourceId: string) {
  try {
    const sections = await mdnScraper.getMDNSections()
    const section = sections.find((s) => s.slug === sectionSlug)

    if (!section) {
      throw new Error(`Section ${sectionSlug} not found`)
    }

    await mdnScraper.scrapeSection(section, jobId)

    // Update source last_scraped_at
    await supabaseAdmin
      .from('knowledge_sources')
      .update({ last_scraped_at: new Date().toISOString() })
      .eq('id', sourceId)
  } catch (error) {
    console.error('Background scraping error:', error)

    await supabaseAdmin
      .from('scraping_jobs')
      .update({
        status: 'failed',
        error_message: error instanceof Error ? error.message : 'Unknown error',
        completed_at: new Date().toISOString(),
      })
      .eq('id', jobId)
  }
}
